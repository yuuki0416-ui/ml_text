{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuki0416-ui/ml_text/blob/main/%E7%AC%AC6%E5%9B%9E%E6%BC%94%E7%BF%92%E8%AA%B2%E9%A1%8CPytorch_Basics_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#機械学習システム第6回課題\n",
        "##62317734\n",
        "##本間勇毅"
      ],
      "metadata": {
        "id": "4b01blimkMUj"
      },
      "id": "4b01blimkMUj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4LdCDYE6Hc3"
      },
      "source": [
        "# PyTorch Basics: 演習ノートブック（簡単な2クラス分類）\n",
        "\n",
        "**PyTorchの基礎**（テンソル、`Dataset`/`DataLoader`、`nn.Module`、最適化、損失、学習ループ、評価）で学んだ内容を、**トピックを** 1つの **簡単な2クラス分類問題** に統合してまとめている。\n",
        "\n",
        "以下は、**動作するベースライン実装** を提供しており、そのまま実行すれば、合成データの分類器が学習・評価される。\n",
        "\n",
        "各項目にある**問**に解答しなさい。\n",
        "\n",
        "このレポートも共通で、LLMは、何らかの形で必ず利用し、このNotebookをそのまま編集して、課題レポートを作成し、PDFとNotebookの両方を提出してください。\n",
        "\n",
        "なお、このNotebookの実行にGPUは不要です。"
      ],
      "id": "d4LdCDYE6Hc3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy3Bc3_f6Hc5"
      },
      "source": [
        "## 0. セットアップ\n",
        "- 依存: `torch`, `matplotlib`\n",
        "- 乱数シードを固定して再現性を担保します。"
      ],
      "id": "iy3Bc3_f6Hc5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "",
          "iopub.execute_input": "",
          "iopub.status.idle": ""
        },
        "id": "n31S3PSw6Hc5"
      },
      "source": [
        "import math\n",
        "import time\n",
        "import itertools\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # さらに厳密な再現性が必要であれば以下も（ただし速度低下の可能性）\n",
        "    torch.use_deterministic_algorithms(False)\n",
        "    return seed\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = set_seed(1234)\n",
        "DEVICE, SEED"
      ],
      "outputs": [],
      "id": "n31S3PSw6Hc5",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSei_WsJ6Hc6"
      },
      "source": [
        "## 1. 合成データの生成と可視化\n",
        "2次元入力 $\\mathbf{x}=(x_1,x_2)$ の2クラス分類を行う\n",
        "\n",
        "2つの “月（moons）” 形状のデータをPyTorchで生成"
      ],
      "id": "jSei_WsJ6Hc6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCF80DBG6Hc6"
      },
      "source": [
        "@torch.no_grad()\n",
        "def make_two_moons(n_samples=2000, noise=0.2, radius=1.0, distance=0.5):\n",
        "    # 上半月\n",
        "    angles1 = torch.rand(n_samples//2) * math.pi\n",
        "    x1 = torch.stack([\n",
        "        torch.cos(angles1),\n",
        "        torch.sin(angles1)\n",
        "    ], dim=1) * radius\n",
        "    # 下半月（少し平行移動）\n",
        "    angles2 = torch.rand(n_samples - n_samples//2) * math.pi\n",
        "    x2 = torch.stack([\n",
        "        1 - torch.cos(angles2),\n",
        "        1 - torch.sin(angles2) - distance\n",
        "    ], dim=1) * radius\n",
        "\n",
        "    X = torch.cat([x1, x2], dim=0)\n",
        "    y = torch.cat([\n",
        "        torch.zeros(x1.size(0), dtype=torch.long),\n",
        "        torch.ones(x2.size(0), dtype=torch.long)\n",
        "    ], dim=0)\n",
        "    X += noise * torch.randn_like(X)\n",
        "    return X, y\n",
        "\n",
        "X_all, y_all = make_two_moons(n_samples=3000, noise=0.25, radius=1.0, distance=0.5)\n",
        "perm = torch.randperm(X_all.size(0))\n",
        "X_all, y_all = X_all[perm], y_all[perm]\n",
        "\n",
        "n_train = int(0.7 * len(X_all))\n",
        "n_val = int(0.15 * len(X_all))\n",
        "X_train, y_train = X_all[:n_train], y_all[:n_train]\n",
        "X_val, y_val = X_all[n_train:n_train+n_val], y_all[n_train:n_train+n_val]\n",
        "X_test, y_test = X_all[n_train+n_val:], y_all[n_train+n_val:]\n",
        "\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "# クラスラベルで色分け、train/val/testをマーカーで区別\n",
        "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, s=20, marker='o', label='train', alpha=0.6, edgecolors='k', linewidth=0.3)\n",
        "plt.scatter(X_val[:,0], X_val[:,1], c=y_val, s=30, marker='s', label='val', alpha=0.7, edgecolors='k', linewidth=0.3)\n",
        "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, s=30, marker='^', label='test', alpha=0.7, edgecolors='k', linewidth=0.3)\n",
        "plt.colorbar(label='Class')\n",
        "plt.legend()\n",
        "plt.title('Two Moons (train/val/test)')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()"
      ],
      "outputs": [],
      "id": "DCF80DBG6Hc6",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ki8ECkd6Hc6"
      },
      "source": [
        "# 問1\n",
        "\n",
        "この結果から、データは **線形分離可能** といえるか。**根拠** として図の特徴（曲線的な境界の必要性など）を簡潔に説明しなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "1Ki8ECkd6Hc6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUVOIs9W6Hc6"
      },
      "source": [
        "## 2. `Dataset` と `DataLoader`\n",
        "`TensorDataset` を使わず、学習用の **簡単な自作 `Dataset`** を用意します（読みやすさ重視）。"
      ],
      "id": "SUVOIs9W6Hc6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glJvZZbI6Hc6"
      },
      "source": [
        "class MoonsDataset(Dataset):\n",
        "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
        "        self.X = X.float()\n",
        "        self.y = y.long()\n",
        "    def __len__(self):\n",
        "        return self.X.size(0)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "batch_size = 64\n",
        "train_ds = MoonsDataset(X_train, y_train)\n",
        "val_ds   = MoonsDataset(X_val, y_val)\n",
        "test_ds  = MoonsDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_ds, batch_size=batch_size)\n",
        "\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ],
      "outputs": [],
      "id": "glJvZZbI6Hc6",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM1B6UoK6Hc7"
      },
      "source": [
        "# 問2\n",
        "\n",
        "バッチサイズを 32 / 64 / 256 に変更した場合、**1エポックの反復回数** はどのようになるか、次のセルの出力を **根拠** に、式とともに答えなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "FM1B6UoK6Hc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lci1rXzh6Hc7"
      },
      "source": [
        "def iters_per_epoch(dataset_size, batch):\n",
        "    return math.ceil(dataset_size / batch)\n",
        "\n",
        "dataset_size = len(train_ds)\n",
        "for b in [32, 64, 256]:\n",
        "    print(f\"batch={b}: iters/epoch={iters_per_epoch(dataset_size, b)} (dataset_size={dataset_size})\")"
      ],
      "outputs": [],
      "id": "Lci1rXzh6Hc7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdtEmTOD6Hc7"
      },
      "source": [
        "## 3. モデル：2層MLP\n",
        "非線形活性化 `ReLU` を用いた2層MLP（隠れ層1つ）を定義します。"
      ],
      "id": "AdtEmTOD6Hc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm27EkK16Hc7"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim=2, hidden=32, out_dim=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP(in_dim=2, hidden=32, out_dim=2).to(DEVICE)\n",
        "model"
      ],
      "outputs": [],
      "id": "Pm27EkK16Hc7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdpVMJ576Hc7"
      },
      "source": [
        "# 問3\n",
        "\n",
        "このMLPの **総パラメータ数** を式で示し、次セルの出力を **根拠** に検算しなさい。\n",
        "\n",
        "なお、パラメータ数は、`Linear(2→32)` の重み・バイアス、`Linear(32→2)` の重み・バイアスの合計とする。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "SdpVMJ576Hc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82QYW7tB6Hc7"
      },
      "source": [
        "def count_params(m: nn.Module):\n",
        "    return sum(p.numel() for p in m.parameters())\n",
        "\n",
        "print('Total params:', count_params(model))\n",
        "for n, p in model.named_parameters():\n",
        "    print(n, p.shape, p.numel())"
      ],
      "outputs": [],
      "id": "82QYW7tB6Hc7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFboU-_k6Hc7"
      },
      "source": [
        "## 4. 学習ルーチン（ベースライン）\n",
        "損失は `CrossEntropyLoss`、最適化は `Adam` を用います。学習率や正則化は後続の演習で扱います。"
      ],
      "id": "WFboU-_k6Hc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DmRluRR6Hc7"
      },
      "source": [
        "@dataclass\n",
        "class TrainConfig:\n",
        "    epochs: int = 50\n",
        "    lr: float = 1e-2\n",
        "    weight_decay: float = 0.0  # L2正則化\n",
        "\n",
        "def train(model, train_loader, val_loader, cfg: TrainConfig):\n",
        "    model = model.to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    hist = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running += loss.item() * xb.size(0)\n",
        "        train_loss = running / len(train_loader.dataset)\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_running, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                val_running += loss.item() * xb.size(0)\n",
        "                pred = logits.argmax(dim=1)\n",
        "                correct += (pred == yb).sum().item()\n",
        "                total += yb.size(0)\n",
        "        val_loss = val_running / len(val_loader.dataset)\n",
        "        val_acc = correct / total\n",
        "\n",
        "        hist['train_loss'].append(train_loss)\n",
        "        hist['val_loss'].append(val_loss)\n",
        "        hist['val_acc'].append(val_acc)\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(f\"epoch {epoch:3d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.3f}\")\n",
        "    return hist\n",
        "\n",
        "cfg = TrainConfig(epochs=50, lr=1e-2, weight_decay=0.0)\n",
        "baseline_model = MLP().to(DEVICE)\n",
        "hist = train(baseline_model, train_loader, val_loader, cfg)"
      ],
      "outputs": [],
      "id": "2DmRluRR6Hc7",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbk7Ge46Hc7"
      },
      "source": [
        "fig = plt.figure(figsize=(6,4))\n",
        "plt.plot(hist['train_loss'], label='train_loss')\n",
        "plt.plot(hist['val_loss'], label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Learning Curves')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "plt.plot(hist['val_acc'], label='val_acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "id": "QVbk7Ge46Hc7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT65VjPB6Hc7"
      },
      "source": [
        "# 問4\n",
        "\n",
        "学習曲線から **過学習の兆候** は見られるか？**根拠** として `train_loss` と `val_loss` の関係、および `val_acc` の挙動を挙げて説明しなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "lT65VjPB6Hc7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U59Zi7s66Hc7"
      },
      "source": [
        "## 5. テストセットでの評価と混同行列\n",
        "学習済みモデルの性能をテストセットで評価し、混同行列を描画します。"
      ],
      "id": "U59Zi7s66Hc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeA3rIZS6Hc7"
      },
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    all_pred, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            logits = model(xb)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "            all_pred.append(pred.cpu())\n",
        "            all_true.append(yb.cpu())\n",
        "    acc = correct / total\n",
        "    return acc, torch.cat(all_true), torch.cat(all_pred)\n",
        "\n",
        "test_acc, y_true, y_pred = evaluate(baseline_model, test_loader)\n",
        "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
        "\n",
        "def confusion_matrix(y_true, y_pred, num_classes=2):\n",
        "    cm = torch.zeros((num_classes, num_classes), dtype=torch.int64)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        cm[t, p] += 1\n",
        "    return cm\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, num_classes=2)\n",
        "print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "for (i, j) in itertools.product(range(cm.size(0)), range(cm.size(1))):\n",
        "    plt.text(j, i, int(cm[i, j]), ha='center', va='center')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "outputs": [],
      "id": "EeA3rIZS6Hc7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnvXU6iG6Hc7"
      },
      "source": [
        "# 問5\n",
        "\n",
        "混同行列から、どちらのクラスで誤分類が相対的に多いか、**根拠** を示して述べて説明しなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "LnvXU6iG6Hc7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kba13vn_6Hc8"
      },
      "source": [
        "## 6. ハイパーパラメータの影響：学習率・L2・バッチサイズ\n",
        "学習率（`lr`）、L2正則化（`weight_decay`）、バッチサイズの違いが性能に与える影響を簡易に比較します。"
      ],
      "id": "Kba13vn_6Hc8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9dQ8IFY6Hc8"
      },
      "source": [
        "def quick_train_eval(lr=1e-2, weight_decay=0.0, batch=64, epochs=30):\n",
        "    # 新しいDataLoader（バッチサイズだけ変える）\n",
        "    train_loader_q = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
        "    val_loader_q   = DataLoader(val_ds, batch_size=batch)\n",
        "    test_loader_q  = DataLoader(test_ds, batch_size=batch)\n",
        "    m = MLP().to(DEVICE)\n",
        "    h = train(m, train_loader_q, val_loader_q, TrainConfig(epochs=epochs, lr=lr, weight_decay=weight_decay))\n",
        "    test_acc, _, _ = evaluate(m, test_loader_q)\n",
        "    return h, test_acc\n",
        "\n",
        "grid = {\n",
        "    'lr': [1e-3, 1e-2, 5e-2],\n",
        "    'weight_decay': [0.0, 1e-4, 1e-3],\n",
        "    'batch': [32, 64]\n",
        "}\n",
        "\n",
        "results = []\n",
        "for lr in grid['lr']:\n",
        "    for wd in grid['weight_decay']:\n",
        "        for b in grid['batch']:\n",
        "            print(f\"=== lr={lr}, weight_decay={wd}, batch={b} ===\")\n",
        "            h, acc = quick_train_eval(lr=lr, weight_decay=wd, batch=b, epochs=25)\n",
        "            results.append({'lr': lr, 'weight_decay': wd, 'batch': b,\n",
        "                            'best_val_acc': max(h['val_acc']), 'final_val_acc': h['val_acc'][-1],\n",
        "                            'test_acc': acc})\n",
        "\n",
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.sort_values(['test_acc','best_val_acc'], ascending=False, inplace=True)\n",
        "df_results.reset_index(drop=True, inplace=True)\n",
        "df_results"
      ],
      "outputs": [],
      "id": "x9dQ8IFY6Hc8",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKMg3qr46Hc8"
      },
      "source": [
        "# 問6\n",
        "\n",
        "上表を **根拠** に、`lr`、`weight_decay`、`batch` が **汎化性能（test_acc）** に与える影響を簡単にまとめなさい。このとき、併せて、`val_acc` の推移と整合しているかも考察しなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "iKMg3qr46Hc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jHh6zlf6Hc8"
      },
      "source": [
        "## 7. 決定境界の可視化\n",
        "学習した分類器の決定境界を描画し、データ散布とともに確認します。"
      ],
      "id": "4jHh6zlf6Hc8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuvl6uoU6Hc8"
      },
      "source": [
        "def plot_decision_boundary(model, X, y, title='Decision Boundary', steps=300):\n",
        "    model.eval()\n",
        "    x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5\n",
        "    y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5\n",
        "    xx = torch.linspace(x_min, x_max, steps)\n",
        "    yy = torch.linspace(y_min, y_max, steps)\n",
        "    grid = torch.stack(torch.meshgrid(xx, yy, indexing='xy'), dim=-1).reshape(-1, 2)\n",
        "    with torch.no_grad():\n",
        "        logits = model(grid.to(DEVICE))\n",
        "        pred = logits.argmax(dim=1).cpu().reshape(steps, steps)\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    plt.contourf(xx, yy, pred, alpha=0.3)\n",
        "    plt.scatter(X[:,0], X[:,1], c=y, s=8)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('x1'); plt.ylabel('x2')\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(baseline_model, X_test, y_test, title='Baseline Decision Boundary (Test)')"
      ],
      "outputs": [],
      "id": "iuvl6uoU6Hc8",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktrPgAbX6Hc8"
      },
      "source": [
        "### Exercise 7（観察）\n",
        "- 決定境界の形状を観察し、**非線形性** の必要性について簡潔に述べてください。\n",
        "\n",
        "_以下に解答を書く_"
      ],
      "id": "ktrPgAbX6Hc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-FhwxhC6Hc8"
      },
      "source": [
        "## 8. 保存と復元（`state_dict`）\n",
        "学習済みモデルを保存し、復元して再評価します。"
      ],
      "id": "j-FhwxhC6Hc8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D_eGiqG6Hc8"
      },
      "source": [
        "save_path = 'baseline_mlp_state.pt'\n",
        "torch.save(baseline_model.state_dict(), save_path)\n",
        "print('saved to', save_path)\n",
        "\n",
        "loaded = MLP().to(DEVICE)\n",
        "loaded.load_state_dict(torch.load(save_path, map_location=DEVICE))\n",
        "acc_loaded, _, _ = evaluate(loaded, test_loader)\n",
        "print('Reloaded Test Accuracy:', acc_loaded)"
      ],
      "outputs": [],
      "id": "1D_eGiqG6Hc8",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCIIXBe6Hc8"
      },
      "source": [
        "#問8\n",
        "\n",
        "復元後の精度は保存前と一致しているか、**根拠** として数値を示し、差が出る可能性があるケース（例えばBatchNormなど状態を持つ層を導入した場合）も言及しなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "LRCIIXBe6Hc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFga9kp66Hc8"
      },
      "source": [
        "## 9. 再現性とシード\n",
        "乱数シードを変えると初期値が変わり、性能がぶれることがあります。軽く検証します。"
      ],
      "id": "pFga9kp66Hc8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jckZbzZo6Hc8"
      },
      "source": [
        "def run_with_seed(seed):\n",
        "    set_seed(seed)\n",
        "    m = MLP().to(DEVICE)\n",
        "    h = train(m, train_loader, val_loader, TrainConfig(epochs=30, lr=1e-2))\n",
        "    acc, _, _ = evaluate(m, test_loader)\n",
        "    return max(h['val_acc']), acc\n",
        "\n",
        "seeds = [2023, 2024, 2025]\n",
        "records = []\n",
        "for s in seeds:\n",
        "    best_val, test_acc = run_with_seed(s)\n",
        "    records.append({'seed': s, 'best_val_acc': best_val, 'test_acc': test_acc})\n",
        "import pandas as pd\n",
        "df_seeds = pd.DataFrame(records)\n",
        "df_seeds"
      ],
      "outputs": [],
      "id": "jckZbzZo6Hc8",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lANCZ_hz6Hc8"
      },
      "source": [
        "# 問9\n",
        "\n",
        "シードによる性能のばらつきを **表（上セル）** を根拠に一言でまとめ、再現性確保のための一般的な実務上の工夫（種の固定、実験回数、平均と標準偏差の報告など）について述べなさい。\n",
        "\n",
        "以下にセルを追加して解答しなさい。"
      ],
      "id": "lANCZ_hz6Hc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxshpjOJ6Hc8"
      },
      "source": [
        "# 問10\n",
        "\n",
        "活性化関数を `Tanh`/`LeakyReLU` に変更し、**可視化や表** を用いて **根拠** を明示しつつ、その効果について説明しなさい。"
      ],
      "id": "UxshpjOJ6Hc8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "created": "2025-11-11T07:50:59.607095Z",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}